#!/usr/bin/env python3
import numpy as np
import pandas as pd
import sys
import os
#import re
import pysam
import gzip
import csv
import json
import yaml



def test_read(read, mut_dict):
	"""
	test if mutations listed in mut_dict are present in the pysam read
	
	returns a list with:
		found_site:	list of site present in the read (no matter content)
		found_mut:	list of those position which have the mutations variant
	"""

	# WARNING pysam is 0-based! (see here: https://pysam.readthedocs.io/en/latest/faq.html#pysam-coordinates-are-wrong )

	# 1. check which mutation' sites are in range of that read 
	found_site = [p for p,m in mut_dict.items() if read.reference_start <= (p-1) <= (read.reference_end-len(m))]
	if not len(found_site):
		return (None, None) # sites aren't present no point checking variants

	# 2. of those sites, check which content mutations' variants
	read_dict = dict(zip(read.get_reference_positions(full_length=True), read.query_sequence))

	found_mut = []
	for p in found_site:
		l=len(mut_dict[p]) #lenght
		# base present ?
		srch=[(p-1+i) in read_dict for i in range(l)]
		if all(srch): # all positions found!
			# check if it's the expected mutation(s)
			if all([read_dict[p-1+i] == mut_dict[p][i] for i in range(l)]):
				found_mut.append(p)
		elif not any(srch): # none position found! (entire deletion)
			# check if we're hunting for a string of deletions (-)
			if '-' * l == mut_dict[p]:
				found_mut.append(p)
		# TODO give some thoughs about partial deletions

	if len(found_mut): # found mutation as sites
		return (found_site, found_mut)
	else: # sites present, but no mutation found
		return (found_site, None)

# scan an amplicon for a specific set of mutations
def scanamplicon(read_iter, mut_dict):
	# TODO inefficient, could be streamed (with an accumulator for pairs)
	reads = dict()
	for read in read_iter:
		name=str(read.query_name)
		R='R1' if read.is_read1 else 'R2'
		if name in reads:
			reads[name][R] = read
		else:
			reads[name] = { R: read }

	print("amplion:", len(reads))

	# tally the mutation sites and the presence of variant in there accross all reads
	# TODO merge with above
	all_muts=[]
	all_sites=[]
	for rds in reads:
		val=reads[rds]
		site_out = []
		mut_out = []
		for s in val:
			R=val[s]
			(t_pos, t_read) = test_read(R, mut_dict)
			if t_pos is not None:
				site_out.extend(t_pos)
			if t_read is not None:
				mut_out.extend(t_read)
		if (len(site_out)):
			all_sites.append(site_out)
			if (len(mut_out)):
				all_muts.append(mut_out)

	sites_cnt=np.unique([len(set(mut)) for mut in all_sites], return_counts=True)
	print("sites:",	len(all_sites),	sites_cnt)
	muts_cnt=np.unique([len(set(sit)) for sit in all_muts], return_counts=True)
	print("muts:",	len(all_muts),	muts_cnt)

	# look at last column only
	return {
		"sites": dict(zip(sites_cnt[0].tolist(),sites_cnt[1].tolist())) if len(all_sites) else {},
		"muts":  dict(zip(muts_cnt[0].tolist(),muts_cnt[1].tolist())) if len(all_muts) else {}
	}


# TODO better naming
def scanbam(sample, batch, amplicons):
	alnfname=f"working/samples/{sample}/{batch}/alignments/REF_aln.bam"
	amp_results={}
	with pysam.AlignmentFile(alnfname, "rb") as alnfile:
		for amp_name,amp in amplicons.items():
			(rq_b,rq_e,mut_dict)=amp

			# we need at least 2 to compute co-occurence
			if len(mut_dict) < 1: # HACK 2:
				continue

			print(f"amplicon_{amp_name}", rq_b, rq_e, mut_dict, sep='\t', end='\t')

			amplicon_iter = alnfile.fetch(rq_chr, rq_b, rq_e)
			amp_results[amp_name] = scanamplicon(amplicon_iter, mut_dict)
	return amp_results


# hardcode
# TODO compute from mutations
amplicons={
 '72_UK': [21718, 21988, {21765: '------', 21991: '---'}],
 '78_UK': [23502, 23810, {23604: 'A', 23709: 'T'}],
 '92_UK': [27827, 28102, {27972: 'T', 28048: 'T', 28111: 'G'}],
 '93_UK': [28147, 28414, {28111: 'G', 28280: 'CTA'}],
 '76_SA': [22879, 23142, {23012: 'A', 23063: 'T'}],
# '76_UK': [22879, 23142, {23063: 'T',23271: 'A'}],
 '77_EU': [23194, 23464, {23403: 'G'}],
}
amplicon_nfo={
 '72_UK': '21765-21770Δ,21991-21993Δ',
 '78_UK': '23604A,23709T',
 '92_UK': '27972T,28048T,28111G',
 '93_UK': '28111G,28280-28280->CTA',
 '76_SA': '23012A,23063T',
 '77_EU': '23403G',
}
rq_chr='NC_045512.2'
t='ww.tsv'
#t='ww-short.tsv'

i=0
table={}
# TODO real jobs instead of a loop
with open(t,'rt',encoding='utf-8') as tf:	# this file has the same content as the original experiment
	for r in csv.DictReader(tf, dialect='excel-tab'):
		#i+=1
		#if (i==3):
			#break;

		print(r['sample'])
		table[r['sample']]=scanbam(r['sample'],r['batch'],amplicons)


#
# dumps, for being able to take it from here
#
print(table)
with open('scanned_mut.json', 'wt') as jf:
	json.dump(obj=table, fp=jf)
with open('scanned_mut.yaml', 'wt') as yf:
	print(yaml.dump(table), file=yf)

# raw data into pands.DataFrame
raw_table_df=pd.DataFrame.from_dict(data={i: {(j,k): table[i][j][k] for j in table[i] for k in table[i][j]} for i in table},
	 orient='index')
#with pd.option_context('display.max_rows', None): #, 'display.max_columns', None):
	#print(raw_table_df)
raw_table_df.to_csv('scanned_mut_raw.csv', sep="\t", compression={'method':'infer'})


#
# pretty output
#

# save to pandas.DataFrame
df_dict={}

# pretty print
l=max(len(k) for k in table)
print(f"{'':<{l}} ", end='')
for a in amplicons: print(f" {a :<26}", end='')
print(f"\n{'':<{l}} ", end='')
for a in amplicons: print(f" {amplicon_nfo[a] :<26}", end='')
print(f"\n{'sample:':<{l}} ", end='')
for a in amplicons: print(f"{'cov:' :>9}{'mut:' :>9}{'frq/%:' :>9}", end='')
print()

for sam,amplicons in table.items():
	df_dict[sam]={}
	print(f"{sam :>{l}} ", end='')

	for ampname,amp in amplicons.items():
		# get topmost
		sites_cnt_l=-1
		sites_cnt=0
		if amp['sites']: # empty ?
			(sites_cnt_l,sites_cnt)=list(amp['sites'].items())[-1]
		muts_cnt_l=-1
		muts_cnt=0
		if amp['muts']: # empty ?
			(muts_cnt_l,muts_cnt)=list(amp['muts'].items())[-1]

		# pack into dict for pandas
		df_dict[sam].update({
			(ampname,'sites'): sites_cnt if sites_cnt else 'NA',
			(ampname,'muts'): muts_cnt if muts_cnt else 'NA',
			(ampname,'res'): (f"{100*muts_cnt/sites_cnt :.2f}%" if muts_cnt_l == sites_cnt_l else  f"({muts_cnt_l}/{sites_cnt_l})") if sites_cnt and muts_cnt else 'NA',
		})

		# pretty print
		if sites_cnt:
			print(f"{sites_cnt :>9}",end='')
			if muts_cnt:
				if muts_cnt_l != sites_cnt_l:
					print(f"\x1b[33;1m{muts_cnt :>9}{f'({muts_cnt_l}/{sites_cnt_l})' :>9}\x1b[0m",end='')
				else:
					print(f"\x1b[32;1m{muts_cnt :>9}{100*muts_cnt/sites_cnt :8.2f}%\x1b[0m",end='')
			else:
				print(f"\x1b[31;1m{'N/A' :>9}{'N/A' :>9}\x1b[0m", end='')
		else:
			print(f"\x1b[31;1m{'N/A' :>9}{'N/A' :>9}{'N/A' :>9}\x1b[0m", end='')

	print()

# pretty into pands.DataFrame
pretty_table_df=pd.DataFrame.from_dict(data=df_dict, orient='index')
#with pd.option_context('display.max_rows', None): #, 'display.max_columns', None):
	#print(pretty_table_df)
pretty_table_df.to_csv('scanned_mut_pretty.csv', sep="\t", compression={'method':'infer'})
